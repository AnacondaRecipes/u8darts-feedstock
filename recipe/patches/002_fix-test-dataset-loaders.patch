Mon Sep 17 00:00:00 2001
From: Lorenzo Pirritano <lpirritano@anaconda.com>
Date: Tue, 17 Oct 2023 18:56:53 +0200
Subject: [PATCH] add 3 retries when testing downloading dataset files

This patch add 3 retries when testing downloading dataset files
because on large files, sometimes the connection gets interrupted.

Only the test source code gets patched. Ideally the two downloaders
_download_dataset and _download_zip_dataset in dataset_loaders.py
should be fixed (downloading in chunks should reduce connection's drops).

---
diff --git a/darts/tests/datasets/test_dataset_loaders.py b/darts/tests/datasets/test_dataset_loaders.py
index 8fd076b8..5ddcf6d6 100644
--- a/darts/tests/datasets/test_dataset_loaders.py
+++ b/darts/tests/datasets/test_dataset_loaders.py
@@ -39,6 +39,13 @@ from darts.datasets.dataset_loaders import (
     DatasetLoaderMetadata,
     DatasetLoadingException,
 )
+from darts.logging import get_logger
+import warnings
+
+logger = get_logger(__name__)
+download_error_msg = (
+    "Could not download the dataset {} during tests. " "Attempt {}/{}. Reason: {}"
+)
 
 datasets = [
     AirPassengersDataset,
@@ -140,9 +147,27 @@ class TestDatasetLoader:
         width, dataset_cls = dataset_config
         dataset = dataset_cls()
         assert dataset._DEFAULT_DIRECTORY == tmp_dir_dataset
-        ts: TimeSeries = dataset.load()
-        assert ts.width == width
-        assert os.path.exists(os.path.join(tmp_dir_dataset, dataset._metadata.name))
+        max_attempts = 3
+        for i in range(1, max_attempts + 1):
+            try:
+                ts: TimeSeries = dataset.load()
+                assert ts.width == width
+                assert os.path.exists(
+                    os.path.join(tmp_dir_dataset, dataset._metadata.name)
+                )
+                break
+            except DatasetLoadingException as e:
+                if str(e).startswith("Could not download the dataset."):
+                    warnings.warn(
+                        download_error_msg.format(
+                            dataset._metadata.uri, i, max_attempts, e.__repr__()
+                        ),
+                        UserWarning,
+                    )
+                    if i == max_attempts:
+                        raise e
+                else:
+                    raise e
 
     def test_hash(self, tmp_dir_dataset):
         with pytest.raises(DatasetLoadingException):
@@ -173,8 +198,29 @@ class TestDatasetLoader:
         )
 
     def test_multi_series_dataset(self):
-        # processing _to_multi_series takes a long time. Test function with 5 cols.
-        ts = ele_multi_series_dataset.load().pd_dataframe()
+        ts = None
+        max_attempts = 3
+        for i in range(1, max_attempts + 1):
+            try:
+                # processing _to_multi_series takes a long time. Test function with 5 cols.
+                ts = ele_multi_series_dataset.load().pd_dataframe()
+                break
+            except DatasetLoadingException as e:
+                if str(e).startswith("Could not download the dataset."):
+                    warnings.warn(
+                        download_error_msg.format(
+                            ele_multi_series_dataset._metadata.uri,
+                            i,
+                            max_attempts,
+                            e.__repr__(),
+                        ),
+                        UserWarning,
+                    )
+                    if i == max_attempts:
+                        raise e
+                else:
+                    raise e
+        assert ts is not None
 
         ms = ElectricityDataset()._to_multi_series(ts)
         assert len(ms) == 5
